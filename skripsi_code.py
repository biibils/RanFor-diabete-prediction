# -*- coding: utf-8 -*-
"""Skripsi-Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HeEOy_uu0OwOGwFSO9NXRgmocmZrT3rY
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

"""# Pengambilan Data"""

df = pd.read_csv('/content/diabetes.csv')
df.head()

"""# Eksplorasi Data"""

df.info()

df.describe(include='all')

"""Checking Missing Value"""

df.isnull().sum()

miss = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin','BMI', 'DiabetesPedigreeFunction']
df[miss].isin([0]).sum()

sns.countplot(x = df['Outcome'])
df['Outcome'].value_counts()

sns.pairplot(df,hue='Outcome')

sns.distplot(df['Glucose'])

sns.distplot(df['BloodPressure'])

sns.distplot(df['SkinThickness'])

sns.distplot(df['Insulin'])

sns.distplot(df['BMI'])

corr = df.corr()

sns.heatmap(corr, annot=True)
sns.set(font_scale=0.9)
plt.show()

"""# Data Preprocessing"""

# mengisi data 0 dengan nilai tengah
from sklearn.impute import SimpleImputer
si = SimpleImputer(missing_values = np.NaN, strategy="median")
df[miss] = si.fit_transform(df[miss])

df.isnull().sum()

df.info()

# mengatasi jumlah data yang tidak seimbang
from sklearn.utils import resample
data_major = df[(df['Outcome']==0)]
data_minor = df[(df['Outcome']==1)]
upsample = resample(data_minor,
                    replace = True,
                    n_samples = 500,
                    random_state= 42)
df_re = pd.concat([upsample, data_major])

sns.countplot(x = df_re['Outcome'])
df_re['Outcome'].value_counts()

# membagi data latih dan data uji 8:2

X = df.drop('Outcome',axis = 1)
y = df['Outcome']

Xr = df_re.drop('Outcome',axis = 1)
yr = df_re['Outcome']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2529)
Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr, yr, test_size=0.2, random_state=2529)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

Xr_train.shape, Xr_test.shape, yr_train.shape, yr_test.shape

# normalisasi data sehingga setiap variabel berdistribusi normal (0,1)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()

X_train = ss.fit_transform(X_train)
X_test = ss.fit_transform(X_test)

Xr_train = ss.fit_transform(Xr_train)
Xr_test = ss.fit_transform(Xr_test)

"""# Pemodelan"""

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(criterion='entropy', n_estimators = 100, max_features='auto')

rf.fit(X_train,y_train)

pred_rf = rf.predict(X_test)

rf_re = RandomForestClassifier(criterion='entropy', n_estimators = 100, max_features='auto')

rf_re.fit(Xr_train,yr_train)

pred_rf_re = rf_re.predict(Xr_test)

pred_rf

pred_rf_re

"""# Evaluasi"""

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
print(classification_report(y_test,pred_rf))
print(confusion_matrix(y_test,pred_rf))

print(classification_report(yr_test,pred_rf_re))
print(confusion_matrix(yr_test,pred_rf_re))

cm = confusion_matrix(y_test,pred_rf)
sns.heatmap(cm, cbar = False, fmt = 'g', annot = True)
print('Accuracy Score = ',round(accuracy_score(y_test,pred_rf),4))

cm = confusion_matrix(yr_test,pred_rf_re)
sns.heatmap(cm, cbar = False, fmt = 'g', annot = True)
print('Accuracy Score = ',round(accuracy_score(yr_test,pred_rf_re),4))